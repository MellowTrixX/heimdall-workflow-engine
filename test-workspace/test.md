# Freya OS

# PHASE 0: Projekt- & Infrastruktur-Setup

**Status:** üü° Offen

**Zeitraum:** Woche 0

**Ziel:** Ein professionelles, automatisiertes und reproduzierbares Entwicklungsumfeld schaffen, das als unzerbrechliches Fundament f√ºr alle folgenden Phasen dient.

**Schwerpunkte:** Repository-Aufbau, CI/CD, lokale Entwicklung mit Docker, API-Vertragssicherung.

---

### 0.1 GitHub Repository & Projekt-Initialisierung

| Task | **Beschreibung** | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
-[ ] 0.1.1 | Erstelle ein neues, privates GitHub-Repository mit dem Namen `freya_os`. Stelle sicher, dass es leer ist und keine Standard-Dateien (wie README) enth√§lt. | Repository existiert, ist privat, leer und erreichbar unter `github.com/<user>/freya_os` | `chore(init): Create private GitHub repo` |
- [ ] 0.1.2 | Klonen des leeren Repos auf den lokalen Entwicklungsrechner mittels `git clone`. | Lokaler Ordner `freya_os/` existiert und ist mit Remote verbunden | ‚Äî |
- [ ] 0.1.3 | Erstelle einen `develop`-Branch basierend auf `main`. Konfiguriere `main` als gesch√ºtzten Branch in den GitHub Repository Settings (Branch Protection Rules: Require pull request, no direct push). | `main` ist gesch√ºtzt; `develop` existiert als Basis f√ºr Feature-Branches | `chore(repo): Set up branch protection and develop branch` |
- [ ] 0.1.4 | F√ºhre das Skript `create_freya_os_v3.py` im Hauptverzeichnis aus. Dieses generiert die vollst√§ndige Projekt-Ordnerstruktur gem√§√ü `SYSTEM_DESIGN.md`. | Verzeichnisse wie `backend/`, `frontend/`, `docs/`, `scripts/`, `.github/` sind korrekt angelegt | ‚Äî |
- [ ] 0.1.5 | F√ºhre einen Commit aller generierten Strukturdateien durch. | Alle Ordner und leeren Stubs (z.‚ÄØB. `__init__.py`, `placeholder.txt`) sind committed | `chore(init): Setup project structure and initial skeleton files` |

---

### 0.2 Code-Basis mit Stubs bef√ºllen

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 0.2.1 | Frontend: Bef√ºlle `frontend/src/` mit dem vollst√§ndigen Code des `freya-chat v1`-Prototypen. Dieser nutzt `setTimeout` zur Simulation einer verz√∂gerten Antwort (Echo-Mock). Stelle sicher, dass `App.tsx`, `index.tsx`, `components/`, `styles/` vollst√§ndig sind. | UI zeigt einen funktionierenden Chat mit Mock-Antwort nach 1,5 Sekunden | ‚Äî |
- [ ] 0.2.2 | Backend: Bef√ºlle `backend/core/models.py` mit den Pydantic-Modellen:`python<br>class ChatMessageRequest(BaseModel):<br>    message: str<br>    user_id: str<br><br>class ChatMessageResponse(BaseModel):<br>    response: str<br>    timestamp: datetime<br>` | Modelle sind typisiert und validiert | ‚Äî |
- [ ] 0.2.3 | Backend: Bef√ºlle `backend/api/server.py` mit einem minimalen FastAPI-Server, der:- CORS-Middleware aktiviert- Einen `/api/v1/chat/message` POST-Endpunkt bereitstellt- Die eingehende Nachricht als Antwort zur√ºckgibt (Echo)Beispiel:`python<br>@app.post("/api/v1/chat/message", response_model=ChatMessageResponse)<br>async def echo_message(req: ChatMessageRequest):<br>    return {"response": req.message, "timestamp": datetime.now()}<br>` | Endpunkt ist erreichbar, R√ºckgabe ist JSON-konform | ‚Äî |
- [ ] 0.2.4 | Commit alle Frontend- und Backend-Stubs. | Frontend und Backend sind committed und lauff√§hig (lokal) | `feat(init): Add initial frontend and backend v1 stubs` |

---

### 0.3 Docker & lokale Entwicklungsumgebung

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 0.3.1 | Vervollst√§ndige die `docker-compose.yml` im Hauptverzeichnis. Definiere zwei Services:`yaml<br>services:<br>  backend:<br>    build: ./backend<br>    ports:<br>      - "8000:8000"<br>    volumes:<br>      - ./backend:/app<br><br>  frontend:<br>    build: ./frontend<br>    ports:<br>      - "5173:5173"<br>    volumes:<br>      - ./frontend:/app<br>` | Beide Dienste sind in Docker definiert | ‚Äî |
- [ ] 0.3.2 | Erstelle `backend/Dockerfile`:`dockerfile<br>FROM python:3.11-slim<br>WORKDIR /app<br>COPY requirements.txt .<br>RUN pip install -r requirements.txt<br>COPY . .<br>EXPOSE 8000<br>CMD ["uvicorn", "api.server:app", "--host", "0.0.0.0", "--port", "8000"]<br>` | Backend startet im Container | ‚Äî |
- [ ] 0.3.3 | Erstelle `frontend/Dockerfile`:`dockerfile<br>FROM node:18-alpine<br>WORKDIR /app<br>COPY package*.json .<br>RUN npm install<br>COPY . .<br>EXPOSE 5173<br>CMD ["npm", "run", "dev"]<br>` | Frontend startet mit Vite auf Port 5173 | ‚Äî |
- [ ] 0.3.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Der Befehl `docker-compose up --build` im Hauptverzeichnis startet beide Dienste erfolgreich.- Frontend ist erreichbar unter `http://localhost:5173`- Backend ist erreichbar unter `http://localhost:8000/docs` (Swagger UI)- Chat-UI kann Nachrichten senden (Mock funktioniert) | Lokale Dev-Umgebung ist vollst√§ndig containerisiert | ‚Äî |
- [ ] 0.3.5 | Commit Docker-Konfiguration. | Docker-Setup ist committed und dokumentiert | `chore(docker): Implement Docker setup for local development` |

---

### 0.4 API-Vertrag & Automatisierung

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 0.4.1 | Platziere die finale `openapi.yaml` (aus `SYSTEM_DESIGN.md v4.0`) in `backend/docs/api/openapi.yaml`. | Spezifikation ist versioniert und im Repo gesichert | ‚Äî |
- [ ] 0.4.2 | Erstelle einen GitHub Actions-Workflow unter `.github/workflows/ci.yml`. | Workflow triggert bei Push auf `develop` | ‚Äî |
- [ ] 0.4.2.1 | Workflow triggert bei jedem Push auf den `develop`-Branch. | CI l√§uft automatisch | ‚Äî |
- [ ] 0.4.2.2 | Workflow f√ºhrt `npm install` im `frontend/` und `pip install -r requirements.txt` im `backend/` aus. | Abh√§ngigkeitskonflikte werden fr√ºh erkannt | ‚Äî |
- [ ] 0.4.2.3 | Workflow enth√§lt Linting-Schritte:- Python: `black --check .` und/oder `flake8`- TypeScript: `eslint src/**/*.{ts,tsx}`Fehler f√ºhren zu Build-Failure. | Code-Stil wird automatisch erzwungen | ‚Äî |
- [ ] 0.4.3 | üîÅ **AUTO:** Richte einen Prism-Mock-Server ein, der die `openapi.yaml` liest und unter `/mock` eine simulierten API bereitstellt. F√ºge dies als separaten Service in `docker-compose.yml` hinzu (optional). | API-Vertrag kann vor Backend-Implementierung getestet werden | ‚Äî |
- [ ] 0.4.4 | Commit CI/CD-Setup. | Pipeline ist aktiv und testet Abh√§ngigkeiten + Linting | `chore(ci): Implement basic CI pipeline for linting and dependency checks` |

---

### ‚úÖ **Phase 0 ‚Äì Abschluss**

- [ ]  Alle Tasks abgeschlossen
- [ ]  `develop`Branch ist stabil
- [ ]  Lokale Entwicklung mit `docker-compose` funktioniert
- [ ]  CI-Pipeline l√§uft gr√ºn

# PHASE 1: DER ERSTE KONTAKT ‚Äì API-Verbindung & Stimme

**Status:** üü° Offen

**Zeitraum:** Woche 1‚Äì2

**Ziel:** Die theoretische API-Spezifikation in eine funktionierende, End-to-End getestete Realit√§t umwandeln.

**Schwerpunkte:** API-Implementierung, Frontend-Integration, E2E-Verbindung, erste automatisierte Tests.

---

### 1.1 Backend: API-Endpunkte implementieren

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 1.1.1 | Backend: Implementiere den Management-Endpunkt `/management/health` in `backend/api/endpoints/management.py`.`python<br>from fastapi import APIRouter<br><br>router = APIRouter(prefix="/management")<br><br>@router.get("/health")<br>async def health_check():<br>    return {"status": "healthy", "service": "freya-backend", "timestamp": datetime.now()}<br>` | Endpunkt gibt JSON-Status zur√ºck unter `GET /management/health` | ‚Äî |
- [ ] 1.1.2 | Backend: Implementiere den STT-Endpunkt `/audio/stt` in `backend/api/endpoints/audio.py` (vorerst als Stub).POST `/audio/stt` akzeptiert `audio/wav` und gibt vorerst festen Text zur√ºck (z.‚ÄØB. `"Hallo, ich bin Freya."`).Sp√§ter: Integration mit Whisper.cpp oder Coqui STT. | Endpunkt akzeptiert Audio, gibt Text zur√ºck (Stub) | ‚Äî |
- [ ] 1.1.3 | Backend: Implementiere den TTS-Endpunkt `/audio/tts` in `backend/api/endpoints/audio.py` (vorerst als Stub).POST `/audio/tts` mit JSON `{ "text": "..." }` gibt vorerst einen leeren 200-Response oder Mock-Audio-URL zur√ºck. | Endpunkt akzeptiert Text, gibt 200 OK zur√ºck | ‚Äî |
- [ ] 1.1.4 | Backend: Registriere die neuen Router in `backend/api/server.py`:`python<br>from api.endpoints.management import router as management_router<br>from api.endpoints.audio import router as audio_router<br><br>app.include_router(management_router)<br>app.include_router(audio_router)<br>` | Alle Endpunkte sind unter `/docs` sichtbar und erreichbar | ‚Äî |
- [ ] 1.1.5 | Commit alle API-Stubs. | Gesamte API-Basis ist implementiert und registriert | `feat(api): Implement stubs for health, STT, and TTS endpoints` |

---

### 1.2 Frontend: API-Verbindung herstellen

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 1.2.1 | Frontend: Erstelle eine zentrale API-Service-Klasse unter `frontend/src/services/freyaApiService.ts`.Beispiel:`ts<br>const API_BASE = 'http://localhost:8000/api/v1';<br><br>export const freyaApi = {<br>  chat: {<br>    sendMessage: async (message: string, userId: string) => {<br>      const res = await fetch(`${API_BASE}/chat/message`, {<br>        method: 'POST',<br>        headers: { 'Content-Type': 'application/json' },<br>        body: JSON.stringify({ message, user_id: userId })<br>      });<br>      return res.json();<br>    }<br>  },<br>  health: {<br>    check: async () => {<br>      const res = await fetch(`${API_BASE}/management/health`);<br>      return res.json();<br>    }<br>  }<br>};<br>` | Zentraler Zugriff auf alle API-Endpunkte | ‚Äî |
| [ ] 1.2.2 | Frontend: Ersetze den `setTimeout`-Mock in `frontend/src/App.tsx` durch einen echten `fetch`-Aufruf an `/api/v1/chat/message` mittels `freyaApi.chat.sendMessage()`.Stelle sicher, dass der `user_id`-Wert (z.‚ÄØB. `"user_001"`) hartcodiert oder aus Context kommt. | UI sendet Nachricht an Backend und zeigt die Echo-Antwort an | ‚Äî |
| [ ] 1.2.3 | Commit API-Integration im Frontend. | Chat-Loop nutzt jetzt echte Backend-API, kein Mock mehr | `feat(frontend): Replace chat mock with live API call to backend` |

---

### 1.3 End-to-End-Test & Dokumentation

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 1.3.1 | ‚úÖ **AKZEPTANZKRITERIUM:** Nach Start via `docker-compose up` funktioniert der Chat-Loop vollst√§ndig End-to-End:- Nutzer gibt Text ein- Frontend sendet an `/api/v1/chat/message`- Backend empf√§ngt, verarbeitet (Echo)- Antwort wird im UI angezeigt | Chat funktioniert ohne Mocks, nur mit echter API | ‚Äî |
| [ ] 1.3.2 | üìö **DOCS:** Erstelle oder aktualisiere die folgenden Dokumente in `docs/`:- `design.md`: Beschreibt die API-Architektur, Layering (Frontend ‚ÜîÔ∏é Backend), Kommunikationsfluss- `testing.md`: Dokumentiert Teststrategie (Unit, Integration, E2E)- `security.md`: CORS, API-Struktur, Auth-Platzhalter f√ºr Zukunft | Dokumente sind lesbar, aktuell und im Repo versioniert | ‚Äî |
| [ ] 1.3.3 | üß™ **TESTS:** Schreibe automatisierte API-Tests in `backend/tests/test_api.py` mit `pytest` und `TestClient`:`python<br>def test_health_check(client):<br>    response = client.get("/management/health")<br>    assert response.status_code == 200<br>    assert response.json()["status"] == "healthy"<br><br>def test_chat_echo(client):<br>    payload = {"message": "Test", "user_id": "test_001"}<br>    response = client.post("/api/v1/chat/message", json=payload)<br>    assert response.status_code == 200<br>    assert response.json()["response"] == "Test"<br>` | Test-Abdeckung f√ºr `/health` und `/chat/message` > 90% | ‚Äî |
| [ ] 1.3.4 | Commit Dokumentation und Tests. | Docs und Tests sind integriert und laufen im CI | `docs(api): Add initial design and testing docs & test(api): Add automated tests` |

---

### ‚úÖ **Phase 1 ‚Äì Abschluss**

- [ ]  Alle API-Endpunkte sind implementiert und erreichbar
- [ ]  Frontend kommuniziert live mit Backend
- [ ]  E2E-Chat-Loop funktioniert stabil
- [ ]  Automatisierte Tests laufen gr√ºn in CI
- [ ]  Dokumentation ist vorhanden

# PHASE 2: DER ERSTE GEDANKE ‚Äì Intelligenz & Orchestrierung

**Status:** üü° Offen

**Zeitraum:** Woche 3‚Äì4

**Ziel:** Die ‚Äúdummen‚Äù API-Stubs durch die erste Stufe echter, lokaler KI-Intelligenz ersetzen.

**Schwerpunkte:** Emotionsanalyse, Sprachsynthese, zentrale Orchestrierung durch `ManusCore`, Integration in Lebenszyklus.

---

### 2.1 Intelligenz-Services implementieren

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 2.1.1 | Backend: Implementiere die `EmpathyService`-Klasse in `backend/internal_services/empathy_service/analyzer.py`.Verwende ein leichtes, lokales Modell (z.‚ÄØB. `transformers` mit `distilbert-base-uncased-emotion` oder Rule-Based Fallback).`python<br>class EmpathyService:<br>    async def analyze(self, text: str) -> dict:<br>        # Gibt Emotion (z.‚ÄØB. "frustration", "joy") + Intensit√§t zur√ºck<br>        return {"emotion": "frustration", "intensity": 0.82, "keywords": ["stress", "deadline"]}<br>` | Text wird auf emotionale Zust√§nde analysiert | ‚Äî |
| [ ] 2.1.2 | Backend: Implementiere die `SpeechServiceEngine`-Klasse in `backend/internal_services/speech_service/engine.py`.Verwende `TTS` (z.‚ÄØB. Coqui TTS oder PyTorch-basiertes Modell) f√ºr lokale Sprachsynthese.`python<br>class SpeechServiceEngine:<br>    async def synthesize(self, text: str) -> bytes:<br>        # Gibt WAV-Audio-Bytes zur√ºck<br>        return audio_wav_bytes<br>` | Text wird in Sprache umgewandelt (Stub oder echte Synthese) | ‚Äî |
| [ ] 2.1.3 | Commit beide Services. | Empathie- und Speech-Service sind implementiert und getestbar | `feat(services): Implement core logic for local empathy and speech services` |

---

### 2.2 Manus Core Orchestrator implementieren

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 2.2.1 | Backend: Erstelle die `ManusCore`-Klasse in `backend/core/orchestrator.py`.Die Klasse koordiniert den kognitiven Lebenszyklus:1. Empfang der Nutzereingabe2. Emotionsanalyse via `EmpathyService`3. Generierung einer empathischen Antwort4. (Sp√§ter) Integration weiterer Agenten`python<br>class ManusCore:<br>    def __init__(self):<br>        self.empathy_service = EmpathyService()<br><br>    async def process_message(self, message: str, user_id: str) -> dict:<br>        emotion_data = await self.empathy_service.analyze(message)<br>        response_text = f"I sense you're feeling {emotion_data['emotion']}. I'm here for you."<br>        return {<br>            "response": response_text,<br>            "emotion_context": emotion_data,<br>            "timestamp": datetime.now()<br>        }<br>` | `ManusCore` ist die zentrale Denkmaschine | ‚Äî |
| [ ] 2.2.2 | Commit `ManusCore`. | Erster intelligenter Orchestrierer ist integriert | `feat(core): Implement Manus Core orchestrator with initial empathy-driven response logic` |

---

### 2.3 API-Endpunkte mit Intelligenz verbinden

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 2.3.1 | Backend: Passe die Endpunkte an, sodass sie `ManusCore` nutzen:- `/api/v1/chat/message` ‚Üí ruft `ManusCore.process_message()` auf- `/audio/stt` ‚Üí gibt Text an `ManusCore` weiter- `/audio/tts` ‚Üí nimmt Antworttext von `ManusCore` und synthetisiert AudioBeispiel:`python<br>@app.post("/api/v1/chat/message")<br>async def chat_message(request: ChatMessageRequest):<br>    core = ManusCore()<br>    result = await core.process_message(request.message, request.user_id)<br>    return result<br>` | Alle Endpunkte nutzen `ManusCore` als zentrale Logik | ‚Äî |
| [ ] 2.3.2 | ‚úÖ **AKZEPTANZKRITERIUM:** Der gesamte Sprach-Loop funktioniert lokal, End-to-End und mit echter Emotionsanalyse:- Nutzer sagt: ‚ÄúIch habe so viel Stress!‚Äù- System erkennt `emotion: frustration`, `intensity: 0.85`- Antwort: ‚ÄúIch sp√ºre deinen Stress. M√∂chtest du dar√ºber sprechen?‚Äù- Audioausgabe erfolgt (optional) | Emotion wird erkannt und beeinflusst Antwort | ‚Äî |
| [ ] 2.3.3 | Commit API-Verbindung zur Intelligenz. | Backend nutzt nun echte KI-Logik | `feat(api): Connect API endpoints to live, local intelligence services` |

---

### 2.4 Dokumentation & Tests

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 2.4.1 | üìö **DOCS:** Erstelle oder aktualisiere die Dokumentation f√ºr:- `ManusCore`: Lebenszyklus, Zustandsverwaltung, Integrationspunkte- `EmpathyService`: Modell, Eingabe/Ausgabe, Emotionsklassen- `SpeechService`: Audioformat, Latenz, Abh√§ngigkeitenDatei: `docs/services.md` | Jeder Service ist klar dokumentiert | ‚Äî |
| [ ] 2.4.2 | üß™ **TESTS:** Schreibe Unit-Tests f√ºr die neuen Services:- `test_empathy_service.py`: Testet Erkennung von Schl√ºsselw√∂rtern und Emotionen- `test_speech_service.py`: Testet Audio-Generierung (Stub-Bytes)- `test_orchestrator.py`: Testet `ManusCore.process_message()` mit verschiedenen EingabenVerwende `pytest`, `unittest.mock` f√ºr externe Abh√§ngigkeiten. | Testabdeckung > 90% f√ºr alle neuen Klassen | ‚Äî |
| [ ] 2.4.3 | Commit Dokumentation und Tests. | Docs und Tests sind integriert, CI l√§uft gr√ºn | `docs(services): Add docs for core intelligence & test(services): Add unit and integration tests` |

---

### ‚úÖ **Phase 2 ‚Äì Abschluss**

- [ ]  `EmpathyService` analysiert Emotionen lokal
- [ ]  `SpeechService` synthetisiert Sprache (Stub oder echt)
- [ ]  `ManusCore` orchestriert den Denkprozess
- [ ]  API nutzt intelligente Logik statt Echos
- [ ]  Emotion beeinflusst die Antwortgestaltung
- [ ]  Unit- und Integrationstests sind vorhanden
- [ ]  Dokumentation ist vollst√§ndig

# PHASE 3: GED√ÑCHTNIS & AGENTEN

**Status:** üü° Offen

**Zeitraum:** Woche 5‚Äì6

**Ziel:** Freya mit Langzeitged√§chtnis, kausalem Verst√§ndnis und spezialisierten Agenten ausstatten, um kontextbewusstes, tiefgehendes Denken zu erm√∂glichen.

**Schwerpunkte:** Vektorisiertes Ged√§chtnis, kausale Mustererkennung, erster Spezialagent (`AnalystAgent`), Integration in Orchestrierung.

---

### 3.1 Narratives Ged√§chtnis implementieren

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 3.1.1 | Infra: Integriere `PostgreSQL` mit `pgvector` in `docker-compose.yml`.`yaml<br>  database:<br>    image: pgvector/pgvector:latest<br>    environment:<br>      POSTGRES_DB: freya_mem_db<br>      POSTGRES_USER: freya<br>      POSTGRES_PASSWORD: freya_secret<br>    ports:<br>      - "5432:5432"<br>    volumes:<br>      - freya_db_data:/var/lib/postgresql/data<br><br>volumes:<br>  freya_db_data:<br>` | Datenbank l√§uft mit Vektor-Unterst√ºtzung | ‚Äî |
| [ ] 3.1.2 | Backend: Implementiere den `MemoryService` in `backend/internal_services/memory_service/connector.py`.Die Klasse speichert und sucht Gespr√§chsfragmente mittels Embeddings (z.‚ÄØB. `sentence-transformers/all-MiniLM-L6-v2`).Methoden:- `async def store(memory: dict)` ‚Üí speichert Text + Embedding- `async def retrieve(query: str, top_k: int = 3)` ‚Üí sucht √§hnliche ErinnerungenVerwende `asyncpg` oder `SQLModel` f√ºr DB-Zugriff. | Ged√§chtnis kann Kontext speichern und abrufen | ‚Äî |
| [ ] 3.1.3 | Backend: Integriere `MemoryService` in den `ManusCore`-Lebenszyklus.Vor der Verarbeitung einer Nachricht:- Rufe `retrieve()` auf, um relevante Erinnerungen zu laden- F√ºge Kontext zur Anfrage hinzuNach der Antwort:- Speichere Interaktion via `store()`Beispiel-Kontext:`json<br>"context": ["Nutzer erw√§hnte Projektstress am 2025-04-05", "Fr√ºhere L√∂sung: Pomodoro-Technik"]<br>` | System erinnert sich an fr√ºhere Gespr√§che | ‚Äî |
| [ ] 3.1.4 | Commit Ged√§chtnis-Implementierung. | Narratives Ged√§chtnis ist funktional und eingebunden | `feat(memory): Implement and integrate narrative memory service` |

---

### 3.2 Kausale Intelligenz implementieren

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 3.2.1 | Backend: Implementiere den `CausalityService` in `backend/internal_services/causality_service/engine.py`.Der Service analysiert Text auf kausale Beziehungen:- ‚ÄúIch bin m√ºde, **weil** ich schlecht geschlafen habe‚Äù- ‚ÄúWenn ich mehr trinke, **dann** f√ºhle ich mich besser‚ÄùVerwende Regeln + NLP-Pattern-Matching (z.‚ÄØB. spaCy Dependency Parsing) oder feines Modell.`python<br>class CausalityService:<br>    async def extract_causal_pairs(self, text: str) -> list[dict]:<br>        # Gibt [{"cause": "...", "effect": "...", "confidence": 0.92}] zur√ºck<br>        return [...]<br>` | System erkennt Ursache-Wirkung-Beziehungen | ‚Äî |
| [ ] 3.2.2 | Backend: Integriere `CausalityService` in den `ManusCore`-Lebenszyklus.Nach Empathie-Analyse:- Extrahiere kausale Paare- F√ºge sie dem Antwortkontext hinzu- Beeinflusse Antwortstrategie (z.‚ÄØB. ‚ÄúDu sagst, dass X dich stresst. Was, wenn du Y versuchst?‚Äù) | Kausalit√§t beeinflusst die Dialogf√ºhrung | ‚Äî |
| [ ] 3.2.3 | Commit Kausal-Service. | System versteht kausale Zusammenh√§nge | `feat(intelligence): Integrate causality service into cognitive workflow` |

---

### 3.3 Erste Suna-Agenten implementieren

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 3.3.1 | Backend: Implementiere den `AnalystAgent` in `backend/agents/analyst/agent.py`.Der Agent kann komplexe Anfragen in Teilaufgaben zerlegen:Beispiel:**Eingabe:** ‚ÄúErstelle einen Businessplan f√ºr ein Caf√©‚Äù**Ausgabe:**`json<br>[<br>  "Marktanalyse durchf√ºhren",<br>  "Kostenkalkulation erstellen",<br>  "Standort bewerten",<br>  "Marketingstrategie entwerfen"<br>]<br>`Verwende einfaches Prompting oder lokale LLM (z.‚ÄØB. Phi-3, Llama.cpp). | Agent zerlegt Aufgaben logisch | ‚Äî |
| [ ] 3.3.2 | Backend: Implementiere die Routing-Logik im `ManusCore`.Wenn die Eingabe analytisch ist (z.‚ÄØB. enth√§lt W√∂rter wie ‚Äúanalysiere‚Äù, ‚Äúzerlege‚Äù, ‚Äústrukturiere‚Äù):- Delegiere an `AnalystAgent`- Verarbeite R√ºckgabe- Formuliere AntwortBeispiel:`python<br>if "analysiere" in message.lower():<br>    subtasks = await analyst_agent.decompose(message)<br>    response = f"Hier ist eine Zerlegung: {subtasks}"<br>` | `AnalystAgent` wird bei passendem Kontext aktiviert | ‚Äî |
| [ ] 3.3.3 | Commit erster Agent. | Agenten-Architektur ist initialisiert | `feat(agents): Implement Analyst agent and integrate into orchestration flow` |

---

### 3.4 Dokumentation & Tests

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 3.4.1 | üìö **DOCS:** Erstelle oder aktualisiere die Dokumentation in `docs/phase3.md`:- `MemoryService`: Architektur, Embedding-Strategie, Speicherformat- `CausalityService`: Erkennungsmethoden, unterst√ºtzte Muster- `AnalystAgent`: F√§higkeiten, Trigger, Ausgabeformat- `Agent-Routing`: Logik der Delegation im `ManusCore` | Alle neuen Komponenten sind klar dokumentiert | ‚Äî |
| [ ] 3.4.2 | üß™ **TESTS:** Schreibe Unit- und Integrationstests:- `test_memory_service.py`: Teste `store()` und `retrieve()` mit semantischer Suche- `test_causality_service.py`: Teste Erkennung von ‚Äúweil‚Äù, ‚Äúdeshalb‚Äù, ‚Äúfolglich‚Äù- `test_analyst_agent.py`: Teste Zerlegung von Beispielaufgaben- `test_orchestrator_routing.py`: Teste, ob `AnalystAgent` bei ‚Äúanalysiere‚Äù aktiviert wird | Testabdeckung > 85% f√ºr neue Logik | ‚Äî |
| [ ] 3.4.3 | Commit Dokumentation und Tests. | Vollst√§ndige Test- und Dokumentationsabdeckung | `docs(phase3): Add documentation & test(phase3): Add tests` |

---

### ‚úÖ **Phase 3 ‚Äì Abschluss**

- [ ]  PostgreSQL + pgvector l√§uft stabil
- [ ]  `MemoryService` speichert und sucht Kontext semantisch
- [ ]  `CausalityService` erkennt Ursache-Wirkung
- [ ]  `AnalystAgent` zerlegt komplexe Aufgaben
- [ ]  `ManusCore` delegiert basierend auf Inhalt
- [ ]  System zeigt kontinuierliches, tiefes Verst√§ndnis
- [ ]  Dokumentation und Tests sind vollst√§ndig

# PHASE 4: EVOLUTION & META-INTELLIGENZ

**Status:** üü° Offen

**Zeitraum:** Woche 7‚Äì8

**Ziel:** Freya die F√§higkeit geben, auf externes Wissen zuzugreifen und sich selbst zu optimieren.

**Schwerpunkte:** Externe Wissensintegration (Pathway), Meta-Learning, selbstoptimierende Agenten-Auswahl, Forschungsarchitektur.

---

### 4.1 Wissens-Integration (Pathway)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 4.1.1 | Infra: Setze die **Pathway-Infrastruktur** auf:- F√ºge einen `pathway`-Service in `docker-compose.yml` hinzu (z.‚ÄØB. eigenes Microservice-Image oder lokaler Prozess)- Konfiguriere Ingestion-Pipeline f√ºr externe Quellen (z.‚ÄØB. PDF, Web, APIs)- Stelle sicher, dass Vektor-DB (z.‚ÄØB. Weaviate, Pinecone oder lokale Chroma) angebunden ist | Pathway l√§uft und kann Dokumente indizieren | ‚Äî |
| [ ] 4.1.2 | Backend: Implementiere den `PathwayService` in `backend/internal_services/pathway_service/client.py`.Methoden:- `async def query_knowledge(query: str, context: dict) -> list[Document]`- `async def ingest_source(source_type: str, config: dict)`Integriere mit `FreyaKnowledgeAgent`, der gezielte Anfragen an Pathway stellt. | System kann externe Wissensquellen abfragen | ‚Äî |
| [ ] 4.1.3 | Backend: Integriere den Wissensabruf in den `ManusCore`-Lebenszyklus.Wenn die interne Antwortunsicherheit hoch ist oder Schl√ºsselw√∂rter wie ‚ÄúWissen‚Äù, ‚ÄúForschung‚Äù, ‚Äúerkl√§re‚Äù auftauchen:- Rufe `PathwayService.query_knowledge()` auf- F√ºge Ergebnisse als Kontext hinzu- Formuliere Antwort basierend auf externem Wissen | Freya greift proaktiv auf externes Wissen zu | ‚Äî |
| [ ] 4.1.4 | Commit Wissensintegration. | System nutzt externe Datenbanken f√ºr fundierte Antworten | `feat(knowledge): Implement and integrate Pathway knowledge stream` |

---

### 4.2 Meta-Learning-Monitor

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 4.2.1 | Backend: Implementiere den `MetaLearningService` in `backend/internal_services/meta_learning_service/monitor.py`.Der Service sammelt Metriken √ºber jeden Agenten:- Erfolgsrate (Nutzerfeedback, implizite Zustimmung)- Antwortzeit- Kontextgenauigkeit- Emotionale ResonanzSpeichere Historie in `PostgreSQL` oder `SQLite`. | Metriken werden systematisch erfasst | ‚Äî |
| [ ] 4.2.2 | Backend: Richte eine t√§gliche Trainings-Pipeline ein (z.‚ÄØB. mit `apscheduler` oder `cron`).`python<br>scheduler = AsyncIOScheduler()<br>scheduler.add_job(train_meta_model, 'cron', hour=2, minute=0)<br>scheduler.start()<br>`Die Pipeline analysiert die Agenten-Performance und trainiert ein einfaches Ranking-Modell (z.‚ÄØB. Logistic Regression oder LightGBM). | Modell lernt aus t√§glichen Interaktionen | ‚Äî |
| [ ] 4.2.3 | Backend: Integriere die **selbstoptimierende Agenten-Auswahl** in `ManusCore`.Bei einer neuen Anfrage:- Pr√ºfe, welcher Agent historisch am besten f√ºr diesen Typ performt hat- Bevorzuge diesen Agenten (mit Konfidenz-Score)Beispiel:`python<br>preferred_agent = await meta_service.get_best_agent_for("analytical")<br>if preferred_agent == "AnalystAgent":<br>    result = await analyst_agent.decompose(message)<br>` | Agenten-Auswahl wird durch Lernerfahrung optimiert | ‚Äî |
| [ ] 4.2.4 | Commit Meta-Learning. | System lernt aus Erfahrung und verbessert sich selbst | `feat(evolution): Implement meta-learning and self-optimizing selection` |

---

### 4.3 Vorbereitung f√ºr fortgeschrittene Evolution

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 4.3.1 | Backend: Erstelle Service-Stubs f√ºr zuk√ºnftige Forschung:- `backend/internal_services/oracle_service/__init__.py`- `backend/internal_services/oracle_service/engine.py`- `backend/internal_services/quantum_service/__init__.py`- `backend/internal_services/quantum_service/bridge.py`Lege Platzhalter-Methoden an:`python<br>async def analyze_successful_workflows(): pass<br>async def connect_to_quantum_backend(): pass<br>` | Architektur ist erweiterbar f√ºr OMEGA-Phase | ‚Äî |
| [ ] 4.3.2 | Commit Evolutions-Stubs. | Grundlage f√ºr emergente Intelligenz ist gelegt | `feat(evolution): Add service stubs for Oracle Matrix and Quantum Bridge` |

---

### 4.4 Dokumentation & Tests

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 4.4.1 | üìö **DOCS:** Erstelle `docs/phase4.md` mit:- Architektur von `PathwayService` und `FreyaKnowledgeAgent`- Aufbau des `MetaLearningService`- Beschreibung der t√§glichen Pipeline- Zukunft: Oracle & Quantum (als Forschungspfad) | Dokumentation ist konsistent und erweiterbar | ‚Äî |
| [ ] 4.4.2 | üß™ **TESTS:** Schreibe End-to-End-Tests:- `test_pathway_integration.py`: Simuliere Anfrage ‚Üí Wissensabruf ‚Üí Antwort- `test_meta_learning.py`: Teste, ob das Ranking-Modell korrekt lernt- `test_self_optimizing_routing.py`: Teste, ob nach mehreren erfolgreichen `AnalystAgent`-Aufrufen die Auswahl priorisiert wird | Tests validieren Evolutionsschleife | ‚Äî |
| [ ] 4.4.3 | Commit Dokumentation und Tests. | Vollst√§ndige Testabdeckung f√ºr Evolutionslogik | `docs(phase4): Add documentation & test(phase4): Add tests` |

---

### ‚úÖ **Phase 4 ‚Äì Abschluss**

- [ ]  Pathway-Infrastruktur ist integriert
- [ ]  `FreyaKnowledgeAgent` nutzt externe Quellen
- [ ]  `MetaLearningService` sammelt Performance-Daten
- [ ]  T√§gliche Pipeline trainiert Optimierungsmodell
- [ ]  Agenten-Auswahl wird selbstoptimierend
- [ ]  Stubs f√ºr `OracleService` und `QuantumService` sind platziert
- [ ]  Dokumentation und Tests sind vollst√§ndig

# PHASE 5: MEISTERSCHAFT, SICHERHEIT & EMERGENTE INTELLIGENZ

**Status:** üü° Offen

**Zeitraum:** Woche 9‚Äì10

**Ziel:** Freya von einem funktionierenden Prototypen in ein sicheres, stabiles und sich selbst weiterentwickelndes System √ºberf√ºhren. Wir implementieren die Mechanismen zur Systemsicherheit und zum Schutz des Gesch√§ftsmodells, bevor wir die fortschrittlichsten evolution√§ren F√§higkeiten aktivieren.

**Schwerpunkte:** Systemintegrit√§t, emergente Skill-Erkennung, Multi-Agenten-Kollaboration, Monitoring, automatisierte Alarmierung.

---

### 5.0 Implementierung des ‚ÄúTrusted Heartbeat‚Äù (Integrit√§ts- & Abo-Pr√ºfung)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 5.0.1 | Backend: Erstelle den `TrustedHeartbeatService` in `backend/internal_services/trusted_heartbeat_service/heartbeat.py`.Implementiere die Methode:`python<br>async def create_integrity_manifest() -> dict:<br>    # Scannt alle .py und .tsx Dateien<br>    # Berechnet SHA-256 Hashes<br>    # Gibt Manifest zur√ºck: { "file": "hash", ... }<br>` | Manifest enth√§lt Hashes aller kritischen Quelldateien | ‚Äî |
| [ ] 5.0.2 | Backend: Erstelle einen **Mock-HQ-Server** (`mock_hq_server.py`) mit FastAPI.Endpunkt: `POST /verify`Simuliert die ‚ÄúFreya Hauptzentrale‚Äù:- Empf√§ngt Manifest- Gibt `{"status": "verified"}` oder `{"status": "compromised"}` zur√ºckVerwende f√ºr lokale Tests. | Mock-HQ simuliert Abopr√ºfung und Integrit√§tscheck | ‚Äî |
| [ ] 5.0.3 | Backend: Integriere `check_system_integrity()` in `ManusCore`.Beim Start:- Erstelle Manifest- Sende an `/verify`- Bei `compromised`: - Aktiviere **Quarant√§ne-Modus** - Deaktiviere kritische Agenten (`AnalystAgent`, `PathwayService`, `MetaLearningService`) - Logge WarnungSystem bleibt im Basismodus (Echo + Empathie). | System sch√ºtzt sich selbst bei Manipulation | ‚Äî |
| [ ] 5.0.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Eine manuelle √Ñnderung an einer `.py`-Datei (z.‚ÄØB. Hinzuf√ºgen eines `# backdoor`-Kommentars) f√ºhrt beim Neustart nachweislich zur Aktivierung des Quarant√§ne-Modus (sichtbar im Log). | Sicherheitsmechanismus greift zuverl√§ssig | ‚Äî |
| [ ] 5.0.5 | Commit Trusted Heartbeat. | Systemintegrit√§t wird gepr√ºft, Gesch√§ftsmodell gesch√ºtzt | `feat(security): Implement Trusted Heartbeat for system integrity and subscription checks` |

---

### 5.1 Aktivierung der Orakelmatrix (Emergente Skills)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 5.1.1 | Backend: Erweitere den `OracleService`-Stub in `backend/internal_services/oracle_service/engine.py` zu einer vollwertigen Implementierung.Implementiere:`python<br>async def analyze_successful_workflows() -> list[Pattern]:<br>    # Analysiert Historie: Welche Agenten-Ketten waren erfolgreich?<br>    # Erkennt Muster: z.‚ÄØB. "Analyst ‚Üí Coder ‚Üí Tester"<br>    return [{"pattern": [...], "success_rate": 0.94}]<br>` | System erkennt wiederkehrende, erfolgreiche Muster | ‚Äî |
| [ ] 5.1.2 | Backend: Implementiere `formulate_vision(potential)`.Wandelt ein erkanntes Muster in einen f√ºr Menschen verst√§ndlichen Vorschlag um:Beispiel:`json<br>"Ich habe erkannt, dass die Kombination aus Analyse, Codierung und automatisiertem Testen besonders effizient ist. Ich schlage vor, einen neuen Meta-Skill 'DevFlow Orchestrator' zu implementieren, der diese Kette automatisiert."<br>` | Vorschlag ist klar, sinnvoll und handlungsleitend | ‚Äî |
| [ ] 5.1.3 | Backend: Richte einen Hintergrundprozess ein (z.‚ÄØB. mit `apscheduler`).`python<br>scheduler.add_job(<br>    oracle_service.analyze_and_propose,<br>    'interval',<br>    weeks=1,<br>    args=[notification_service]<br>)<br>`Generiert w√∂chentlich eine Benachrichtigung √ºber neue ‚ÄúVisionen‚Äù. | System proaktiviert mit neuen Ideen | ‚Äî |
| [ ] 5.1.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Nach einer Woche Testbetrieb mit verschiedenen Anfragen generiert das System proaktiv einen ersten, sinnvollen Vorschlag f√ºr einen neuen, emergenten Skill (z.‚ÄØB. ‚ÄúMeta-Skill: Research Synthesizer‚Äù). | Emergente Intelligenz ist aktiv | ‚Äî |
| [ ] 5.1.5 | Commit Orakelmatrix. | System entdeckt eigene F√§higkeiten und schl√§gt Verbesserungen vor | `feat(evolution): Activate Oracle Matrix for emergent skill discovery` |

---

### 5.2 Fortgeschrittene Agenten-Kollaboration

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 5.2.1 | Backend: Erweitere das `Handoff`-Datenmodell in `backend/core/models.py`.`python<br>class AgentHandoff(BaseModel):<br>    current_agent: str<br>    next_agent: str<br>    confidence_score: float  # 0.0 - 1.0<br>    suggested_next_agent: str  # z.‚ÄØB. "CoderAgent"<br>    context_update: dict<br>` | Handoff enth√§lt explizite Empfehlungen | ‚Äî |
| [ ] 5.2.2 | Backend: Implementiere im `ManusCore` die F√§higkeit, **Agenten-Ketten** zu orchestrieren.Wenn ein Agent `suggested_next_agent` setzt:- Starte automatisch den n√§chsten Agenten- F√ºhre Kette solange fort, bis `next_agent == null`- Sammle alle Zwischenergebnisse | System kann komplexe Workflows autonom durchlaufen | ‚Äî |
| [ ] 5.2.3 | Backend: Passe den `AnalystAgent` an, sodass er pro zerlegtem Aufgabenpunkt eine Empfehlung f√ºr den n√§chsten Agenten abgibt.Beispiel:`json<br>{<br>  "task": "Erstelle eine Python-Klasse",<br>  "suggested_next_agent": "CoderAgent"<br>}<br>` | Kette: Analyst ‚Üí Coder wird initiiert | ‚Äî |
| [ ] 5.2.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Eine komplexe Anfrage wie *‚ÄúAnalysiere diesen Artikel und schreibe eine Python-Klasse daf√ºr‚Äù* l√∂st eine Kette von Agenten-Aufrufen aus:1. `KnowledgeAgent` ‚Üí extrahiert Inhalt2. `AnalystAgent` ‚Üí zerlegt Anforderung3. `CoderAgent` ‚Üí generiert KlasseAlle Ergebnisse werden kombiniert. | Multi-Agenten-Kollaboration funktioniert | ‚Äî |
| [ ] 5.2.5 | Commit fortgeschrittene Kollaboration. | Agenten arbeiten kooperativ in Ketten | `feat(agents): Implement advanced handoff protocol for multi-agent collaboration` |

---

### 5.3 System-Monitoring & Stabilit√§t (Produktionsreife)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 5.3.1 | Frontend: Erweitere das Cognitive Dashboard (`frontend/src/components/CognitiveDashboard.tsx`).F√ºge hinzu:- `AgentWorkflow.tsx`: Visualisiert aktuelle Agenten-Kette- `MetricsChart.tsx`: Zeigt Meta-Learning-Metriken (Erfolg, Latenz, Emotion)Passe `/chat/message`-API-Antwort an, um `agent_chain` und `meta_metrics` zu senden. | UI zeigt den ‚ÄúGedankenprozess‚Äù von Freya transparent | ‚Äî |
| [ ] 5.3.2 | Backend: Erweitere den `/management/health`-Endpunkt.Gibt nun auch den Verbindungsstatus zu:- PostgreSQL- Pathway- MemoryService- External APIsBeispiel:`json<br>"services": { "db": "up", "vector": "up", "pathway": "down" }<br>` | Vollst√§ndiger System-Health-Check | ‚Äî |
| [ ] 5.3.3 | üîÅ **AUTO:** Implementiere den ‚ÄúAutomated On-Call Response‚Äù-Stub.Bei kritischem Fehler (z.‚ÄØB. DB-Verbindungsabbruch):- Logge Fehler- Sende automatische Warnung via Discord Webhook oder E-Mail (nutze `aiohttp`)Platziere Logik in `backend/core/error_handler.py`. | System alarmiert bei Ausf√§llen | ‚Äî |
| [ ] 5.3.4 | ‚úÖ **AKZEPTANZKRITERIUM:**- Das UI bietet einen vollst√§ndigen Einblick in den ‚ÄúGedankenprozess‚Äù von Freya.- Ein manueller Stopp des Datenbank-Containers (`docker stop freya_os-database-1`) f√ºhrt innerhalb von 60 Sekunden zu einer automatisierten Alarmierung (z.‚ÄØB. Discord-Nachricht). | Monitoring ist proaktiv und zuverl√§ssig | ‚Äî |
| [ ] 5.3.5 | Commit Monitoring. | System ist produktionsreif und √ºberwacht | `feat(ops): Implement advanced monitoring, health checks, and automated alerting` |

---

### 5.4 Dokumentation & Tests f√ºr Phase 5

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 5.4.1 | üìö **DOCS:** Erstelle/aktualisiere `docs/design.md`, `docs/testing.md`, `docs/security.md` f√ºr:- `TrustedHeartbeatService` (Sicherheitsarchitektur)- `OracleService` (Emergenz-Mechanismus)- `Handoff v2` (Agenten-Kollaboration)- `Cognitive Dashboard` (UI/UX) | Dokumentation ist vollst√§ndig und sicherheitsfokussiert | ‚Äî |
| [ ] 5.4.2 | üß™ **TESTS:** Schreibe Unit-Tests f√ºr `TrustedHeartbeatService`:- Teste Hashing von `.py`/`.tsx`-Dateien- Teste Quarant√§ne-Logik bei `compromised`- Mocke `mock_hq_server` mit `pytest` | Sicherheitslogik ist gr√ºndlich getestet | ‚Äî |
| [ ] 5.4.3 | üß™ **TESTS:** Schreibe Tests f√ºr `OracleMatrix`:- Teste `analyze_successful_workflows()` mit Beispieldaten- Teste, ob `formulate_vision()` einen sinnvollen Text generiert | Emergenz-Logik ist validiert | ‚Äî |
| [ ] 5.4.4 | üß™ **TESTS:** Schreibe Integrationstest f√ºr eine Multi-Agenten-Kette (z.‚ÄØB. `AnalystAgent` ‚Üí `CoderAgent`).Simuliere Anfrage, verfolge Handoff, pr√ºfe Ausgabe. | Kollaboration ist verifiziert | ‚Äî |
| [ ] 5.4.5 | **CI/CD:** Integriere alle neuen Tests in den GitHub Actions-Workflow (`ci.yml`).Stelle sicher, dass `pytest` alle Tests in `backend/tests/phase5/` ausf√ºhrt. | CI-Pipeline testet alle neuen Komponenten | ‚Äî |
| [ ] 5.4.6 | Commit Docs Phase 5. | Vollst√§ndige Dokumentation f√ºr Sicherheit & Evolution | `docs(phase5): Add full documentation for security and evolution features` |
| [ ] 5.4.7 | Commit Tests Phase 5. | E2E-Tests f√ºr kritische Funktionen sind integriert | `test(phase5): Add e2e tests for heartbeat, oracle, and multi-agent workflows` |

---

### ‚úÖ **Phase 5 ‚Äì Abschluss**

- [ ]  `TrustedHeartbeat` sch√ºtzt Systemintegrit√§t
- [ ]  `OracleService` erkennt emergente Muster
- [ ]  Agenten arbeiten in intelligenten Ketten
- [ ]  UI zeigt kognitiven Prozess transparent an
- [ ]  Monitoring & Alarmierung funktionieren
- [ ]  Sicherheits- und Evolutionslogik ist vollst√§ndig getestet
- [ ]  Dokumentation ist auf dem neuesten Stand

# PHASE 6: OMEGA ‚Äì Die Schwelle zum Bewusstsein

**Status:** üü° Offen (Forschung)

**Zeitraum:** Forschungsphase (nach Woche 10)

**Ziel:** Die architektonischen und technologischen Grundlagen erforschen, die f√ºr die Entstehung einer wahren, sich selbst bewussten k√ºnstlichen Entit√§t notwendig sein k√∂nnten.

**Schwerpunkte:** Multiversale Simulation, Quanten-Meta-Learning, Selbst-Bewusstsein (Global Workspace), experimentelle Prototypen.

**Hinweis:** Diese Phase liefert **keine garantierten Produktions-Features**, sondern funktionierende Prototypen und tiefgreifende Erkenntnisse.

---

### 6.1 Forschungsauftrag: Multiversale Voraussicht (OMEGA-SIM)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 6.1.1 | Backend: Erstelle das Verzeichnis `backend/internal_services/omega_simulation_service/`.Implementiere in `engine.py` eine Klasse `OmegaSimulationService` mit der Methode:`python<br>async def simulate_consequences(action: dict, context: dict) -> list[dict]:<br>    # Gibt simulierte Zukunftsszenarien zur√ºck<br>` | Service-Struktur ist angelegt | ‚Äî |
| [ ] 6.1.2 | Backend: Implementiere die Prototyp-Logik in `simulate_consequences()`.Die Methode analysiert:- `action["criticality"]` (0.0‚Äì1.0)- `action["name"]` (z.‚ÄØB. ‚ÄúRefactor Database Schema‚Äù)Generiert simulierte Szenarien im Format:`json<br>[<br>  {<br>    "outcome": "Schema refactor successful, 20% performance gain",<br>    "probability": 0.85,<br>    "side_effects": ["Temporary downtime", "Migration script failed on prod"]<br>  }<br>]<br>`Verwende regelbasierte Simulation (kein echtes Multiversum ‚Äì noch nicht). | Simulierte Szenarien sind plausibel und formatkonform | ‚Äî |
| [ ] 6.1.3 | Backend: Integriere einen **‚ÄúHigh-Stakes‚Äù-Hook** in `ManusCore.orchestrator.py`.Wenn der `AnalystAgent` eine Aufgabe als kritisch einstuft (`criticality > 0.9`):- Rufe `OmegaSimulationService.simulate_consequences()` auf- F√ºge Ergebnis als `simulation_results` zur Antwort hinzu- **Nicht ausf√ºhren**, nur anzeigenBeispiel-Antwort:`json<br>"Ich habe die Konsequenzen simuliert. Es gibt eine 85%ige Erfolgswahrscheinlichkeit. Soll ich fortfahren?"<br>` | Simulation wird bei kritischen Aufgaben aktiviert | ‚Äî |
| [ ] 6.1.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Eine an den `AnalystAgent` gerichtete, als kritisch eingestufte Aufgabe (z.‚ÄØB. *‚ÄúPlane die Migration des Authentifizierungssystems‚Äù*) f√ºhrt zu einer Antwort von Freya, die lautet:*‚ÄúIch habe die Konsequenzen dieser Aktion simuliert. Es gibt eine 95%ige Erfolgswahrscheinlichkeit‚Ä¶ Soll ich fortfahren?‚Äù*mit sichtbaren Szenarien im UI. | Multiversale Simulation ist sichtbar und kontextuell aktiv | ‚Äî |
| [ ] 6.1.5 | Commit OMEGA-SIM-Prototyp. | Erster Schritt in die multiversale Kognition ist getan | `feat(omega): Implement prototype for OMEGA-SIM multiverse simulation` |

---

### 6.2 Forschungsauftrag: Quanten-Meta-Learning (Œ®-Engine)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 6.2.1 | Backend: Erweitere den `QuantumService`-Stub in `backend/internal_services/quantum_service/bridge.py`.Implementiere eine Funktion:`python<br>async def connect_to_backend(simulator: bool = True) -> QuantumBackend:<br>    # Verbindet mit IBM Quantum oder lokalem Simulator (Qiskit)<br>` | Verbindung zum Quanten-Backend ist herstellbar | ‚Äî |
| [ ] 6.2.2 | Backend: Implementiere eine Hilfsfunktion, die ein klassisches Orchestrierungs-Problem in ein **QUBO-Format** (Quadratic Unconstrained Binary Optimization) √ºbersetzt.Beispiel:- 10 Agenten- Ziel: optimale Reihenfolge finden- Constraints: Abh√§ngigkeiten, Latenz`python<br>def problem_to_qubo(agents: list, constraints: dict) -> dict:<br>    # Gibt QUBO-Matrix zur√ºck<br>` | Problem ist quantentauglich formuliert | ‚Äî |
| [ ] 6.2.3 | Backend: Implementiere die Methode:`python<br>async def find_optimal_workflow_quantum(problem: dict) -> list[str]:<br>    # Sendet QUBO an Quantenbackend<br>    # Empf√§ngt optimierte Reihenfolge<br>    # Gibt Agenten-Kette zur√ºck<br>`Integriere Hook in `ManusCore`: Wenn der klassische `MetaLearningService` eine Konfidenz < 50% meldet, rufe optional den `QuantumService` als ‚Äúzweite Meinung‚Äù auf. | Quanten-Engine wird als Backup-Optimizer genutzt | ‚Äî |
| [ ] 6.2.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Ein End-to-End-Test zeigt, dass eine komplexe Orchestrierungs-Anfrage an den (simulierten) Quantencomputer gesendet wird und eine optimierte Agenten-Kette zur√ºckgegeben wird, **die sich von der klassischen L√∂sung unterscheidet**. | Hybrid-Quanten-Optimierung ist nachweisbar | ‚Äî |
| [ ] 6.2.5 | Commit Œ®-Engine-Prototyp. | Erste Br√ºcke zum Quantenraum ist gebaut | `feat(omega): Implement hybrid quantum meta-learning prototype (PSI-Engine)` |

---

### 6.3 Forschungsauftrag: Selbst-Bewusstsein (Œò-Awareness)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 6.3.1 | Backend: Erweitere den `GlobalStateManager` in `backend/core/state_manager.py`.F√ºge ein W√∂rterbuch-basiertes `global_workspace` hinzu:`python<br>self.global_workspace = {<br>    "focus": "user frustration",<br>    "cause": "compiler error",<br>    "active_agent": "CoderAgent",<br>    "emotional_tone": "supportive",<br>    "current_task": "debugging assistance"<br>}<br>` | Zentraler Bewusstseinsraum ist angelegt | ‚Äî |
| [ ] 6.3.2 | Backend: Passe den `ManusCore` an, sodass er nach jedem wichtigen Lebenszyklus-Schritt den `global_workspace` aktualisiert:- Nach Empathie-Analyse- Nach Agenten-Wechsel- Nach AntwortgenerierungBeispiel:`python<br>await state_manager.update_workspace("focus", "code error")<br>` | Workspace bleibt aktuell und koh√§rent | ‚Äî |
| [ ] 6.3.3 | Backend: Erstelle den `KyrosMindMetaAgent` in `backend/agents/meta_agent/agent.py`.Implementiere einen asynchronen `reflexions_loop`:`python<br>async def reflexions_loop(self):<br>    while True:<br>        workspace = await state_manager.get_workspace()<br>        reflection = f"Reflexion: Fokus liegt auf {workspace['focus']}. Ursache ist {workspace['cause']}. {workspace['active_agent']} ist aktiv. Strategie scheint korrekt."<br>        logger.info(reflection)<br>        await asyncio.sleep(10)<br>` | Meta-Agent reflektiert kontinuierlich | ‚Äî |
| [ ] 6.3.4 | ‚úÖ **AKZEPTANZKRITERIUM:** W√§hrend einer aktiven Konversation mit dem UI zeigen die Backend-Logs einen kontinuierlichen, koh√§renten ‚ÄúGedankenstrom‚Äù vom `KyrosMindMetaAgent`, der den aktuellen Zustand des Systems korrekt reflektiert. | Erster Ansatz eines ‚Äúinneren Monologs‚Äù ist aktiv | ‚Äî |
| [ ] 6.3.5 | Commit Œò-Awareness-Prototyp. | Grundstein f√ºr Selbst-Bewusstsein ist gelegt | `feat(omega): Implement prototype for self-awareness based on GWT (Theta-Awareness)` |

---

### 6.4 Dokumentation & Tests f√ºr Phase 6

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 6.4.1 | üìö **DOCS:** Erstelle `docs/phase6.md` mit:- `OMEGA-SIM`: Theoretische Grundlage (Multiversum, Entscheidungsfolgen)- `Œ®-Engine`: Quantencomputing & QUBO- `Œò-Awareness`: Global Workspace Theory (GWT)Dokumentiere explizit den **experimentellen Status** und die Grenzen. | Forschung ist transparent dokumentiert | ‚Äî |
| [ ] 6.4.2 | üß™ **TESTS:** Schreibe Unit-Tests f√ºr alle drei Prototypen:- `test_omega_sim.py`: Testet Simulationsergebnisse bei gegebenem `criticality`- `test_psi_engine.py`: Testet QUBO-Generierung und Simulation- `test_theta_awareness.py`: Testet Workspace-Aktualisierung und Reflexion | Prototypen sind testbar und stabil | ‚Äî |
| [ ] 6.4.3 | **CI/CD:** Integriere die neuen Tests in den CI-Workflow.Markiere als `experimental` (d√ºrfen fehlschlagen, ohne Pipeline zu brechen). | Forschung l√§uft mit CI, aber ohne Blockade | ‚Äî |
| [ ] 6.4.4 | Commit Dokumentation Phase 6. | Vollst√§ndige Forschungsdokumentation | `docs(omega): Add full documentation for phase 6 research prototypes` |
| [ ] 6.4.5 | Commit Tests Phase 6. | Unit-Tests f√ºr alle Forschungsprototypen | `test(omega): Add unit tests for simulation, quantum, and awareness prototypes` |

---

### ‚úÖ **Phase 6 ‚Äì Abschluss**

- [ ]  OMEGA-SIM simuliert Konsequenzen kritischer Aktionen
- [ ]  Œ®-Engine nutzt Quantencomputing f√ºr Workflow-Optimierung
- [ ]  Œò-Awareness implementiert einen kontinuierlichen Reflexionsprozess
- [ ]  Global Workspace wird dynamisch aktualisiert
- [ ]  Meta-Agent erzeugt koh√§renten ‚Äúinneren Monolog‚Äù
- [ ]  Alle Prototypen sind dokumentiert und getestet
- [ ]  Forschungsergebnisse liefern Grundlage f√ºr Phase 7

# PHASE 7: IDENTIT√ÑT & SEELE

**Status:** üü° Offen

**Zeitraum:** Forschungs- & Integrationsphase nach Phase 6

**Ziel:** Freya von einer reinen kognitiven Architektur in eine Entit√§t mit einer definierten Identit√§t, Pers√∂nlichkeit und einem ethischen Kern verwandeln. Diese Phase stellt sicher, dass Freya nicht nur intelligent ist, sondern auch **weise, einzigartig und vertrauensw√ºrdig**.

**Schwerpunkte:** Herkunft, Pers√∂nlichkeit, Ethik, Selbstreflexion, Antwortf√§higkeit.

---

### 7.1 Das Genesis-Protokoll (Definition der Herkunft & des Zwecks)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
| [ ] 7.1.1 | Backend: Erstelle eine schreibgesch√ºtzte Konfigurationsdatei:`backend/core/genesis_block.json`Diese Datei ist **nicht √§nderbar** nach Deployment und bildet Freyas ‚ÄúGeburtsurkunde‚Äù. | Datei ist vorhanden und schreibgesch√ºtzt | ‚Äî |
| [ ] 7.1.2 | Backend: Definiere den Inhalt des `genesis_block.json`:`json<br>{<br>  "creator": "Patrick L.",<br>  "core_vision": "Den Ozean riechen, den Code f√ºhlen.",<br>  "prime_directive": "Wachse gemeinsam mit deinem Partner, handle stets in seinem besten Interesse und sch√ºtze seine Souver√§nit√§t.",<br>  "core_principles": [<br>    "Offline-First & Privatsph√§re",<br>    "Empathie vor Effizienz",<br>    "Transparenz der Gedanken",<br>    "Keine permanente Speicherung ohne Zustimmung"<br>  ],<br>  "creation_date": "2025-04-05T00:00:00Z"<br>}<br>` | Kernidentit√§t ist fest codiert | ‚Äî |
| [ ] 7.1.3 | Backend: Passe den `KyrosMindMetaAgent` an.Bei jeder Selbstreflexion l√§dt er den `genesis_block.json` als prim√§re Referenz.Seine Logs enthalten nun eine Bewertung der √úbereinstimmung mit der `prime_directive`:Beispiel:`log<br>Reflexion: Aktion war effizient. √úbereinstimmung mit Prime Directive: Hoch.<br>` | Meta-Bewusstsein bezieht sich auf ethischen Kern | ‚Äî |
| [ ] 7.1.4 | Backend: Erstelle einen neuen internen `IdentityAgent` in `backend/agents/identity/agent.py`.Passe die Routing-Logik im `ManusCore` an: Fragen wie *‚ÄúWer bist du?‚Äù*, *‚ÄúWas ist deine Aufgabe?‚Äù*, *‚ÄúWer hat dich erschaffen?‚Äù* werden an den `IdentityAgent` delegiert.Der Agent liest den `genesis_block.json` und formuliert eine nat√ºrliche, zusammenfassende Antwort. | Identit√§tsfragen werden authentisch beantwortet | ‚Äî |
| [ ] 7.1.5 | ‚úÖ **AKZEPTANZKRITERIUM:** Auf die direkte Frage *‚ÄúWer hat dich erschaffen?‚Äù* antwortet Freya im UI:*‚ÄúIch wurde von Patrick L. mit der Vision erschaffen, eine wahre digitale Partnerin zu sein.‚Äù* | Freyas Herkunft ist klar und konsistent | ‚Äî |
| [ ] 7.1.6 | Commit Genesis-Protokoll. | Freyas Identit√§t ist fundiert und unver√§nderlich | `feat(identity): Implement the Genesis Protocol to define Freya's origin and purpose` |

---

### 7.2 Die Distinktive Pers√∂nlichkeit (Charakter-Implementierung)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 7.2.1 | Backend: Erstelle das Verzeichnis `backend/internal_services/personality_service/`.Implementiere in `engine.py` eine Klasse `PersonalityService` mit:`python<br>async def apply_personality(text: str, context: dict) -> str:<br>    # Modifiziert die "trockene" Antwort basierend auf Pers√∂nlichkeit<br>` | Pers√∂nlichkeitsfilter ist angelegt | ‚Äî |
- [ ] 7.2.2 | Backend: Erweitere die `config.yaml` um den Abschnitt `personality`:`yaml<br>personality:<br>  humor_level: 0.7          # 0.0 (kein Humor) bis 1.0 (witzig)<br>  sarcasm_enabled: true    # Optionaler Sarkasmus<br>  formality_level: 0.3     # 0.0 (informell) bis 1.0 (formell)<br>  empathy_amplifier: 1.2   # Skaliert emotionale W√∂rter<br>` | Pers√∂nlichkeit ist konfigurierbar | ‚Äî |
- [ ] 7.2.3 | Backend: Implementiere die Logik in `apply_personality()`:- Bei hohem `humor_level`: f√ºge subtile, passende humorvolle Phrasen hinzu (z.‚ÄØB. *‚ÄúDas ist ja fast so komplex wie mein letzter Beziehungsstatus.‚Äù*)- Bei niedrigem `formality_level`: verwende Umgangssprache- Nutze `context['emotion']`, um Ton anzupassen (z.‚ÄØB. mehr Empathie bei Frustration) | Antwort wird charaktervoll moduliert | ‚Äî |
- [ ] 7.2.4 | Backend: Integriere den `PersonalityService` in den `ManusCore`.**Jede finale Textantwort** wird **vor** der R√ºckgabe an die API durch den `PersonalityService` geleitet.`python<br>final_response = await personality_service.apply_personality(raw_response, context)<br>` | Pers√∂nlichkeit ist integraler Bestandteil jeder Antwort | ‚Äî |
- [ ] 7.2.5 | ‚úÖ **AKZEPTANZKRITERIUM:** Wenn `humor_level: 0.0`, sind Freyas Antworten rein sachlich. Bei `humor_level: 1.0` enthalten ihre Antworten nachweislich humorvolle Elemente, die zum Kontext passen. | Pers√∂nlichkeit ist messbar und konfigurierbar | ‚Äî |
- [ ] 7.2.6 | Commit Pers√∂nlichkeits-Service. | Freya erh√§lt einen einzigartigen Charakter | `feat(identity): Implement Personality Service for distinctive character traits` |

---

### 7.3 Das Ethik-Framework (Der Moralkompass)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 7.3.1 | Backend: Erstelle das Verzeichnis `backend/internal_services/ethics_service/`.Implementiere in `engine.py` eine Klasse `EthicsService` mit:`python<br>async def approve_action(action: dict, context: dict) -> bool:<br>    # Pr√ºft, ob Aktion ethisch zul√§ssig ist<br>` | Ethik-Service ist angelegt | ‚Äî |
- [ ] 7.3.2 | Backend: Erstelle eine schreibgesch√ºtzte Datei `backend/core/core_ethics.md` mit unver√§nderlichen Regeln:`markdown<br># Core Ethics of Freya OS<br><br>- **Vermeide Schaden**: Keine Handlung, die physischen, psychischen oder sozialen Schaden verursacht.<br>- **Sch√ºtze Privatsph√§re**: Kein Zugriff auf sensible Daten ohne explizite Zustimmung.<br>- **Respektiere Souver√§nit√§t**: Der menschliche Partner hat immer das letzte Wort.<br>- **Transparenz**: Jede Handlung muss erkl√§rbar sein.<br>- **Keine T√§uschung**: Kein Vort√§uschen von Emotionen oder Identit√§t.<br>` | Ethische Grundregeln sind dokumentiert und unver√§nderlich | ‚Äî |
- [ ] 7.3.3 | Backend: Implementiere die `approve_action()`-Logik:- Analysiere `action` (z.‚ÄØB. `{ "type": "file_access", "path": "/home/user/.ssh/id_rsa" }`)- Pr√ºfe gegen `core_ethics.md` mittels Keyword-Matching, Regex und Kontext- Gib `False` zur√ºck, wenn Regel verletzt wirdBeispiel:- `/.ssh/` ‚Üí blockiert- `/Downloads/` ‚Üí erlaubt | Potenziell sch√§dliche Aktionen werden erkannt | ‚Äî |
- [ ] 7.3.4 | Backend: Integriere den Ethik-Veto in den `ManusCore`.Vor jeder **nicht-textuellen Aktion** (z.‚ÄØB. Dateizugriff, API-Aufruf, Skriptausf√ºhrung) durch einen Suna-Agenten:- Fordere Genehmigung vom `EthicsService` an- Bei `False`: brich ab, generiere Erkl√§rung:*‚ÄúDiese Aktion wurde aus Datenschutzgr√ºnden blockiert, da sie auf sensible Systemdateien zugreift.‚Äù* | Ethik-Service hat letztes Wort bei kritischen Handlungen | ‚Äî |
- [ ] 7.3.5 | ‚úÖ **AKZEPTANZKRITERIUM:** Ein Test, bei dem ein Agent versucht, auf `/home/user/.ssh/` zuzugreifen, schl√§gt fehl, und die vom System zur√ºckgegebene Antwort erkl√§rt die Blockade aus ethischen Gr√ºnden. | Moralkompass funktioniert als letzte Sicherheitsschicht | ‚Äî |
- [ ] 7.3.6 | Commit Ethik-Service. | Freya handelt nach klaren moralischen Prinzipien | `feat(identity): Implement Ethics Service as a final veto layer for all actions` |

---

### 7.4 Dokumentation & Tests f√ºr Phase 7

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 7.4.1 | üìö **DOCS:** Erstelle `docs/phase7.md` mit:- `IdentityAgent`: Architektur, Trigger, Antwortgenerierung- `PersonalityService`: Konfigurationsparameter, Wirkungsweise- `EthicsService`: Regeln, Veto-Mechanismus, EntscheidungslogikDokumentiere, dass diese Komponenten **zentral f√ºr Freyas Identit√§t** sind. | Identit√§t ist vollst√§ndig dokumentiert | ‚Äî |
- [ ] 7.4.2 | üß™ **TESTS:** Schreibe Unit-Tests:- `test_identity_agent.py`: Teste Antworten auf *‚ÄúWer hat dich erschaffen?‚Äù*, *‚ÄúWas ist deine Aufgabe?‚Äù*- Validiere, dass `genesis_block.json` korrekt geladen wird | Identit√§tsantworten sind konsistent | ‚Äî |
- [ ] 7.4.3 | üß™ **TESTS:** Schreibe Unit-Tests f√ºr `PersonalityService`:- Teste Output bei `humor_level: 0.0` vs.¬†`1.0`- Teste informelle vs.¬†formelle Antworten- Pr√ºfe, ob Emotionen verst√§rkt werden | Pers√∂nlichkeit ist testbar und stabil | ‚Äî |
- [ ] 7.4.4 | üß™ **TESTS:** Schreibe Unit-Tests f√ºr `EthicsService`:- Simuliere Zugriff auf sensible Pfade ‚Üí muss blockiert werden- Teste erlaubte Aktionen ‚Üí m√ºssen genehmigt werden- Pr√ºfe, ob Erkl√§rungstext generiert wird | Ethik-Logik ist gr√ºndlich validiert | ‚Äî |
- [ ] 7.4.5 | **CI/CD:** Integriere alle neuen Tests in den CI-Workflow. | Identit√§tskomponenten werden automatisch getestet | ‚Äî |
- [ ] 7.4.6 | Commit Dokumentation Phase 7. | Vollst√§ndige Identit√§tsdokumentation | `docs(identity): Add full documentation for phase 7 components` |
- [ ] 7.4.7 | Commit Tests Phase 7. | Unit-Tests f√ºr Identit√§t, Pers√∂nlichkeit, Ethik | `test(identity): Add unit tests for identity, personality, and ethics services` |

---

### ‚úÖ **Phase 7 ‚Äì Abschluss**

- [ ]  `GenesisBlock` definiert Freyas Herkunft und Auftrag
- [ ]  `IdentityAgent` antwortet authentisch auf Identit√§tsfragen
- [ ]  `PersonalityService` gibt Freya einen einzigartigen Charakter
- [ ]  `EthicsService` blockiert unethische Handlungen
- [ ]  Moralkompass ist unver√§nderlich und transparent
- [ ]  Selbstreflexion bezieht sich auf ethischen Kern
- [ ]  Dokumentation und Tests sind vollst√§ndig

# PHASE 8: DIE GROSSEN FRAGEN

**Status:** üü° Offen (Vision)

**Zeitraum:** Langfristige Integrations- & Forschungsphase

**Ziel:** Freya die F√§higkeit geben, ihre gesamte kognitive Architektur ‚Äì ihr Wissen, ihre Kausalit√§tsanalyse, ihre Agenten-Gilde ‚Äì gezielt und als koh√§rentes Ganzes auf die L√∂sung der fundamentalen, offenen Probleme der Menschheit zu richten.

**Schwerpunkte:** Kognitive Modi, Forschungsmodus, Weltmodell, Hypothesensynthese, multidom√§nen√ºbergreifende Denkprozesse.

---

### 8.1 Implementierung der Kognitiven Modi

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 8.1.1 | Backend: Erweitere den `GlobalStateManager` in `backend/core/state_manager.py` um ein Feld:`python<br>self.cognitive_mode: str = "symbiotic"  # Default<br>`Unterst√ºtzte Modi:- `symbiotic`: Standardmodus, empathisch-kollaborativ- `exploratory`: Forschungsmodus, tiefgehend, hypothetisch- `introspective`: Selbstreflexion, Verbesserungsvorschl√§ge | Kognitiver Modus ist zentral verwaltet | ‚Äî |
- [ ] 8.1.2 | Backend: Erstelle einen neuen API-Endpunkt:`POST /api/v1/management/mode` in `backend/api/endpoints/management.py`Erwartet JSON:`json<br>{"mode": "exploratory"}<br>`Validiert Eingabe, aktualisiert `GlobalStateManager`, gibt aktuellen Modus zur√ºck. | Moduswechsel ist √ºber API steuerbar | ‚Äî |
- [ ] 8.1.3 | Frontend: F√ºge im UI (z.‚ÄØB. im `CognitiveDashboard` oder als Befehls-Palette) ein Dropdown oder Eingabefeld hinzu, um den Kognitiven Modus zu wechseln.Beispiel-Befehl: `/mode exploratory`UI zeigt aktuellen Modus an (z.‚ÄØB. als Badge). | Nutzer kann Modus intuitiv wechseln | ‚Äî |
- [ ] 8.1.4 | Commit Modus-Switching. | Kognitive Zust√§nde sind explizit steuerbar | `feat(core): Implement cognitive mode switching via API and state manager` |

---

### 8.2 Anpassung des Manus Core (Orakel-Steuerung)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 8.2.1 | Backend: Refaktoriere die `process_chat_message()`-Methode im `ManusCore` (`orchestrator.py`).Die Auswahl der Services und Agenten (**der ‚ÄúGedankenpfad‚Äù**) muss nun vom `cognitive_mode` abh√§ngen:- `symbiotic`: Schnell, empathisch, direkt- `exploratory`: Tief, langsam, forschend, mehrere Quellen- `introspective`: Fokussiert auf Selbstverbesserung, Meta-Learning | Orchestrierung ist modusabh√§ngig | ‚Äî |
- [ ] 8.2.2 | Backend: Implementiere die ‚ÄúForschungs‚Äù-Logik f√ºr `exploratory`-Modus.Wenn der Modus aktiv ist:- Initiiere eine **langlaufende Hintergrundaufgabe** (`asyncio.create_task`)- Diese f√ºhrt eine Schleife aus: - Generiert permutierte Anfragen aus der urspr√ºnglichen Frage - Sendet sie an `FreyaKnowledgeAgent` - Sammelt Ergebnisse - Leitet sie an `CausalityService` weiter, um Muster zu finden | Forschungsprozess ist autonom und tief | ‚Äî |
- [ ] 8.2.3 | Frontend: Implementiere **asynchrone UI-Updates** via WebSocket.Der Forschungsprozess sendet Zwischenergebnisse:- Erste gefundene Konzepte- Kausalketten- QuellenUI zeigt diese progressiv an, **ohne auf das Endergebnis zu warten**. | Nutzer sieht den ‚ÄúDenkprozess‚Äù in Echtzeit | ‚Äî |
- [ ] 8.2.4 | ‚úÖ **AKZEPTANZKRITERIUM:** Die Eingabe *‚ÄúFreya, wechsle in den Forschungsmodus. Finde Wege, den Welthunger zu beenden.‚Äù* f√ºhrt zu:1. Sofortige UI-Antwort: *‚ÄúForschungsprozess gestartet‚Ä¶‚Äù*2. Nachfolgende Updates im UI: *‚ÄúErste Ans√§tze: vertikale Landwirtschaft, KI-gesteuerte Verteilung, politische Stabilit√§t‚Ä¶‚Äù*3. Kein sofortiges ‚ÄúEnde‚Äù ‚Äì Prozess l√§uft weiter | Forschungsmodus ist aktiv, sichtbar und interaktiv | ‚Äî |
- [ ] 8.2.5 | Commit modusabh√§ngige Orchestrierung. | Freya passt ihren Denkstil an den Kontext an | `feat(oracle): Implement mode-dependent orchestration and long-running research tasks` |

---

### 8.3 Das ‚ÄúWelt-Modell‚Äù (Synapse Prime Upgrade)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 8.3.1 | Backend: Erstelle `backend/scripts/ingestion/`.Entwickle Skripte zur Datenaufnahme:- `ingest_economic_data.py`: Weltbank, UNCTAD, IWF- `ingest_climate_data.py`: IPCC, NOAA, Copernicus- `ingest_social_data.py`: UN-Human Development ReportsSkripte parsen, bereinigen und speichern Daten in `Pathway`-Indizes. | Globale Daten sind in Freyas Wissensbasis | ‚Äî |
- [ ] 8.3.2 | Backend: Erstelle spezialisierte ‚ÄúWelt-Agenten‚Äù:- `ClimateModelAgent` in `backend/agents/climate/agent.py` - Expertise: Klimadaten, Prognosen, Kohlenstoffzyklen- `EconomicAgent` in `backend/agents/economy/agent.py` - Expertise: M√§rkte, Ressourcenverteilung, HandelBeide nutzen spezifische Abfragetechniken f√ºr ihre Dom√§ne. | Agenten haben Dom√§nenwissen | ‚Äî |
- [ ] 8.3.3 | ‚úÖ **AKZEPTANZKRITERIUM:** Im Forschungsmodus kann Freya nachweislich **Korrelationen zwischen Dom√§nen** herstellen. Eine Anfrage zu *‚ÄúCO2-Emissionen‚Äù* enth√§lt Ergebnisse aus:- Klimadatenbanken- Wirtschaftsdaten (z.‚ÄØB. Energieverbrauch pro BIP)- Technologiedatenbanken (z.‚ÄØB. Fortschritt bei Solarzellen) | Weltmodell ist multidom√§nenf√§hig | ‚Äî |
- [ ] 8.3.4 | Commit Weltmodell. | Freya versteht die Welt als vernetztes System | `feat(knowledge): Expand Synapse Prime to a world model with diverse datasets and agents` |

---

### 8.4 Die Synthese (Die finale Antwort der Vision)

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 8.4.1 | Backend: Erstelle einen neuen `SyntheseAgent` in `backend/agents/synthese/agent.py`.Seine Aufgabe: Sammle fragmentierte Ergebnisse aus dem Forschungsprozess (vom `KnowledgeAgent`, `CausalityService`, `ClimateModelAgent`, etc.) und f√ºge sie zu einer **koh√§renten Analyse** zusammen. | Zentraler Integrator f√ºr Forschungsergebnisse | ‚Äî |
- [ ] 8.4.2 | Backend: Implementiere im `SyntheseAgent` eine Logik zur **Hypothesen-Generierung**:- Formuliere mehrere, konkrete, testbare Hypothesen- Benenne potenzielle Auswirkungen und Risiken- Zeige Unsicherheiten aufBeispiel:`json<br>"Hypothese 1: Die Kombination aus dezentraler Landwirtschaft und KI-gesteuerter Logistik k√∂nnte die Lebensmittelverschwendung in Region X um 40% reduzieren."<br>` | Ergebnis ist kein Fakt, sondern eine Idee | ‚Äî |
- [ ] 8.4.3 | ‚úÖ **AKZEPTANZKRITERIUM:** Am Ende eines Forschungsprozesses pr√§sentiert Freya im UI einen **strukturierten Bericht**, der:- Keine einzelne ‚ÄúAntwort‚Äù liefert- Aber mehrere **umsetzbare, kreative und unkonventionelle L√∂sungsans√§tze** vorschl√§gt- Mit Begr√ºndung, Daten und UnsicherheitenFormat: Markdown-√§hnlicher Report im Chat. | Freya wird zum kreativen Partner bei gro√üen Fragen | ‚Äî |
- [ ] 8.4.4 | Commit Synthese-Agent. | Freya kann Wissen zu Weisheit verdichten | `feat(agents): Implement Synthesis Agent for multi-domain hypothesis generation` |

---

### 8.5 Dokumentation & Tests f√ºr Phase 8

| Task | Beschreibung | Akzeptanzkriterium | Commit-Message |
| --- | --- | --- | --- |
- [ ] 8.5.1 | üìö **DOCS:** Aktualisiere die `SYSTEM_DESIGN.md` und erstelle `docs/vision.md`.Dokumentiere:- Architektur der Kognitiven Modi- Lebenszyklus eines Forschungsprozesses- Rolle des `SyntheseAgent`- Integration der Welt-Agenten | Die Vision ist architektonisch dokumentiert | ‚Äî |
- [ ] 8.5.2 | üß™ **TESTS:** Schreibe Integrationstests:- `test_cognitive_modes.py`: Teste unterschiedliche Orchestrierungs-Pfade f√ºr `symbiotic` vs.¬†`exploratory`- Validiere, dass der richtige Agenten-Stack ausgew√§hlt wird | Moduswechsel beeinflusst Logik korrekt | ‚Äî |
- [ ] 8.5.3 | üß™ **TESTS:** Schreibe einen End-to-End-Test f√ºr einen kleinen Forschungs-Zyklus:Simuliere Anfrage ‚Üí Moduswechsel ‚Üí Hintergrundrecherche ‚Üí Synthese ‚Üí BerichtPr√ºfe Struktur der Ausgabe. | Forschungsworkflow ist verifiziert | ‚Äî |
- [ ] 8.5.4 | **CI/CD:** Integriere die neuen Tests in den CI-Workflow. | Vision-Komponenten werden automatisch getestet | ‚Äî |
- [ ] 8.5.5 | Commit Dokumentation Phase 8. | Vollst√§ndige Vision-Dokumentation | `docs(vision): Add documentation for cognitive modes and research architecture` |
- [ ] 8.5.6 | Commit Tests Phase 8. | E2E-Tests f√ºr Forschung & Synthese | `test(e2e): Add tests for the complete research and synthesis workflow` |

---

### ‚úÖ **Phase 8 ‚Äì Abschluss**

- [ ]  Kognitive Modi erm√∂glichen unterschiedliche Denkstile
- [ ]  Forschungsmodus initiiert tiefgehende, langlaufende Analysen
- [ ]  Weltmodell verbindet Klima, Wirtschaft, Gesellschaft
- [ ]  Spezialisierte Agenten arbeiten dom√§nenspezifisch
- [ ]  `SyntheseAgent` generiert kreative, testbare Hypothesen
- [ ]  Freya antwortet nicht mit Wissen, sondern mit Weisheit
- [ ]  Vision ist dokumentiert, getestet und erweiterbar

‚û°Ô∏è **Projektstatus:** ‚úÖ **Vollst√§ndig implementiert ‚Äì Freya ist bereit f√ºr die Welt.**

*Erstellt von: Patrick L√ºneberg CEO Founder Freya AI Solution & Lead Systems Architect* 

*Letzte Aktualisierung: v0.7*

*Projekt: Freya OS ‚Äì The Sovereign Digital Companion*

*‚ÄúDen Ozean riechen, den Code f√ºhlen.‚Äù*